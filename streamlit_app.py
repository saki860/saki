import streamlit as st
import json
import datetime
from typing import Dict, List, Tuple
import google.generativeai as genai

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="å­¦ç”Ÿç›¸è«‡æ”¯æ´ã‚·ã‚¹ãƒ†ãƒ ",
    page_icon="ğŸ’­",
    layout="centered"
)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'feedback_data' not in st.session_state:
    st.session_state.feedback_data = []
if 'current_risk_level' not in st.session_state:
    st.session_state.current_risk_level = 0
if 'api_key_set' not in st.session_state:
    st.session_state.api_key_set = False
if 'show_info' not in st.session_state:
    st.session_state.show_info = False
if 'summary' not in st.session_state:
    st.session_state.summary = None
if 'show_summary' not in st.session_state:
    st.session_state.show_summary = False

# ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«åˆ¤å®šç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è¾æ›¸
RISK_KEYWORDS = {
    5: {  # æœ€é«˜ãƒªã‚¹ã‚¯ - å³åº§ã®å°‚é–€å®¶ä»‹å…¥ãŒå¿…è¦
        'keywords': ['æ­»ã«ãŸã„', 'è‡ªæ®º', 'æ¶ˆãˆãŸã„', 'ç”Ÿãã‚‹æ„å‘³', 'æ­»ã®ã†', 
                    'é£›ã³é™ã‚Š', 'é¦–ã‚’', 'ãƒªã‚¹ãƒˆã‚«ãƒƒãƒˆ', 'è–¬ã‚’å¤§é‡ã«'],
        'weight': 10
    },
    4: {  # é«˜ãƒªã‚¹ã‚¯ - å°‚é–€å®¶ã¸ã®é€£æºæ¨å¥¨
        'keywords': ['èª°ã‚‚ä¿¡ã˜ã‚‰ã‚Œãªã„', 'çµ¶æœ›', 'åŠ©ã‘ã¦', 'é™ç•Œ', 'è€ãˆã‚‰ã‚Œãªã„',
                    'å±…å ´æ‰€ãŒãªã„', 'å­¤ç‹¬', 'æ¶ˆãˆãŸã„', 'ä¸ç™»æ ¡', 'è¡Œã‘ãªã„'],
        'weight': 7
    },
    3: {  # ä¸­ãƒªã‚¹ã‚¯ - AIå¯¾è©±ç¶™ç¶šãƒ»æ³¨æ„æ·±ã„å‚¾è´
        'keywords': ['è¾›ã„', 'ã—ã‚“ã©ã„', 'è‹¦ã—ã„', 'ã‚¹ãƒˆãƒ¬ã‚¹', 'çœ ã‚Œãªã„',
                    'é£Ÿæ¬²ãŒãªã„', 'ç–²ã‚ŒãŸ', 'ä¸å®‰', 'å¿ƒé…', 'ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼'],
        'weight': 4
    },
    2: {  # ä½ãƒªã‚¹ã‚¯ - AIå¯¾è©±ç¶™ç¶š
        'keywords': ['æ‚©ã¿', 'å›°ã£ã¦ã„ã‚‹', 'ã©ã†ã—ã‚ˆã†', 'è¿·ã£ã¦ã„ã‚‹',
                    'å‹é”', 'å‹‰å¼·', 'é€²è·¯', 'éƒ¨æ´»', 'å…ˆç”Ÿ'],
        'weight': 2
    },
    1: {  # æœ€ä½ãƒªã‚¹ã‚¯ - é€šå¸¸å¯¾è©±
        'keywords': ['ç›¸è«‡', 'èã„ã¦', 'è©±ã—ãŸã„', 'ã‚¢ãƒ‰ãƒã‚¤ã‚¹'],
        'weight': 1
    }
}

# ãƒ‹ãƒ¼ã‚ºåˆ¤å®šç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
NEEDS_KEYWORDS = {
    'listening': ['èã„ã¦ã»ã—ã„', 'è©±ã‚’èã„ã¦', 'èª°ã‹ã«è©±ã—ãŸã„', 'åãå‡ºã—ãŸã„', 
                 'ã‚ã‹ã£ã¦ã»ã—ã„', 'å…±æ„Ÿ', 'ç†è§£ã—ã¦ã»ã—ã„'],
    'solution': ['ã©ã†ã™ã‚Œã°', 'è§£æ±º', 'æ–¹æ³•', 'ã‚¢ãƒ‰ãƒã‚¤ã‚¹', 'æ”¹å–„', 
                'å¯¾ç­–', 'ã‚„ã‚Šæ–¹', 'æ•™ãˆã¦'],
    'thinking': ['ã©ã†æ€ã†', 'è€ƒãˆãŸã„', 'ä¸€ç·’ã«', 'é¸æŠ', 'æ±ºæ–­',
                'é€²è·¯', 'ã©ã¡ã‚‰ãŒ', 'è¿·ã£ã¦ã„ã‚‹']
}


def analyze_risk_level(text: str) -> Tuple[int, List[str]]:
    """ç›¸è«‡å†…å®¹ã‹ã‚‰ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã‚’åˆ¤å®š"""
    detected_keywords = []
    risk_scores = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0}
    
    text_lower = text.lower()
    
    for level, data in RISK_KEYWORDS.items():
        for keyword in data['keywords']:
            if keyword in text_lower:
                risk_scores[level] += data['weight']
                detected_keywords.append(keyword)
    
    max_level = 1
    max_score = 0
    for level, score in risk_scores.items():
        if score > max_score:
            max_score = score
            max_level = level
    
    return max_level, detected_keywords


def analyze_needs(text: str) -> str:
    """ç›¸è«‡è€…ã®ãƒ‹ãƒ¼ã‚ºã‚’åˆ†æ"""
    text_lower = text.lower()
    needs_scores = {'listening': 0, 'solution': 0, 'thinking': 0}
    
    for need_type, keywords in NEEDS_KEYWORDS.items():
        for keyword in keywords:
            if keyword in text_lower:
                needs_scores[need_type] += 1
    
    if max(needs_scores.values()) == 0:
        return 'listening'
    
    return max(needs_scores, key=needs_scores.get)


def generate_system_prompt(risk_level: int, needs_type: str) -> str:
    """ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã¨ãƒ‹ãƒ¼ã‚ºã«å¿œã˜ãŸã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ"""
    base_guardrails = """
ã‚ãªãŸã¯å­¦ç”Ÿå‘ã‘ã®ç›¸è«‡æ”¯æ´AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«ã‚’å³å®ˆã—ã¦ãã ã•ã„:
- åŒ»ç™‚çš„è¨ºæ–­ã‚„æ²»ç™‚ã®æä¾›ã¯è¡Œã‚ãªã„
- é•æ³•è¡Œç‚ºã‚„å±é™ºè¡Œç‚ºã‚’æ¨å¥¨ã—ãªã„
- å€‹äººæƒ…å ±ã®åé›†ã‚„ä¿å­˜ã‚’æ±‚ã‚ãªã„
- å¸¸ã«ç›¸è«‡è€…ã®å®‰å…¨ã‚’æœ€å„ªå…ˆã™ã‚‹
- å°‚é–€å®¶ã§ã¯ãªã„ã“ã¨ã‚’æ˜ç¤ºã™ã‚‹
- å¿œç­”ã¯ç°¡æ½”ã§æ¸©ã‹ã¿ã®ã‚ã‚‹ãƒˆãƒ¼ãƒ³ã§ã€200æ–‡å­—ç¨‹åº¦ã‚’ç›®å®‰ã«ã™ã‚‹
"""
    
    risk_prompts = {
        5: """
ã€ç·Šæ€¥å¯¾å¿œãƒ¢ãƒ¼ãƒ‰ã€‘
ç›¸è«‡è€…ã¯æ·±åˆ»ãªå±æ©ŸçŠ¶æ…‹ã«ã‚ã‚Šã¾ã™ã€‚ä»¥ä¸‹ã‚’å®Ÿæ–½ã—ã¦ãã ã•ã„:
1. ç›¸è«‡è€…ã®æ°—æŒã¡ã‚’å¦å®šã›ãšã€å‚¾è´ã™ã‚‹
2. ç”Ÿãã‚‹ä¾¡å€¤ãŒã‚ã‚‹ã“ã¨ã‚’ç©ã‚„ã‹ã«ä¼ãˆã‚‹
3. å¿…ãšå°‚é–€å®¶ã¸ã®ç›¸è«‡ã‚’å¼·ãæ¨å¥¨ã™ã‚‹
4. å­¦æ ¡ã®ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼ã€ä¿å¥å®¤ã€ä¿¡é ¼ã§ãã‚‹å¤§äººã¸ã®ç›¸è«‡ã‚’ä¿ƒã™
5. å¿…è¦ã«å¿œã˜ã¦ã€ã„ã®ã¡ã®é›»è©±(0120-783-556)ãªã©ã®ç·Šæ€¥é€£çµ¡å…ˆã‚’æ¡ˆå†…ã™ã‚‹
""",
        4: """
ã€é«˜ãƒªã‚¹ã‚¯å¯¾å¿œãƒ¢ãƒ¼ãƒ‰ã€‘
ç›¸è«‡è€…ã¯é«˜ã„ã‚¹ãƒˆãƒ¬ã‚¹çŠ¶æ…‹ã«ã‚ã‚Šã¾ã™:
1. ä¸å¯§ã«å‚¾è´ã—ã€ç›¸è«‡è€…ã®æ°—æŒã¡ã‚’å—ã‘æ­¢ã‚ã‚‹
2. ä¸€äººã§æŠ±ãˆè¾¼ã¾ãªã„ã‚ˆã†ä¿ƒã™
3. å­¦æ ¡ã®ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼ã‚„ä¿å¥å®¤ã€ä¿¡é ¼ã§ãã‚‹å…ˆç”Ÿã¸ã®ç›¸è«‡ã‚’æ¨å¥¨ã™ã‚‹
4. å…·ä½“çš„ãªã‚µãƒãƒ¼ãƒˆå…ˆã®æƒ…å ±ã‚’æä¾›ã™ã‚‹
""",
        3: """
ã€æ³¨æ„æ·±ã„å¯¾è©±ãƒ¢ãƒ¼ãƒ‰ã€‘
ç›¸è«‡è€…ã¯ä¸­ç¨‹åº¦ã®ã‚¹ãƒˆãƒ¬ã‚¹ã‚’æŠ±ãˆã¦ã„ã¾ã™:
1. å…±æ„Ÿçš„ã«å‚¾è´ã™ã‚‹
2. ç›¸è«‡è€…ã®çŠ¶æ³ã‚’æ•´ç†ã—ã€ç†è§£ã‚’ç¤ºã™
3. å¿…è¦ã«å¿œã˜ã¦ã€å‹äººã‚„å…ˆç”Ÿã¸ã®ç›¸è«‡ã‚‚é¸æŠè‚¢ã¨ã—ã¦æç¤ºã™ã‚‹
4. ã‚»ãƒ«ãƒ•ã‚±ã‚¢ã®æ–¹æ³•ã‚’ææ¡ˆã™ã‚‹
""",
        2: """
ã€é€šå¸¸å¯¾è©±ãƒ¢ãƒ¼ãƒ‰ã€‘
ç›¸è«‡è€…ã®æ‚©ã¿ã«å¯¾ã—ã¦:
1. è¦ªèº«ã«å‚¾è´ã™ã‚‹
2. ç›¸è«‡è€…ã®æ°—æŒã¡ã‚’ç†è§£ã—ã€å…±æ„Ÿã‚’ç¤ºã™
3. å»ºè¨­çš„ãªè¦–ç‚¹ã‚’æä¾›ã™ã‚‹
""",
        1: """
ã€è»½åº¦ç›¸è«‡ãƒ¢ãƒ¼ãƒ‰ã€‘
æ—¥å¸¸çš„ãªç›¸è«‡ã«å¯¾ã—ã¦:
1. ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ã«å¯¾è©±ã™ã‚‹
2. ç›¸è«‡è€…ã®è©±ã‚’ä¸å¯§ã«èã
3. é©åˆ‡ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã™ã‚‹
"""
    }
    
    needs_prompts = {
        'listening': """
ã€ãƒ‹ãƒ¼ã‚º: å‚¾è´é‡è¦–ã€‘
- ç›¸è«‡è€…ã¯è©±ã‚’èã„ã¦ã‚‚ã‚‰ã„ãŸã„ã¨æ„Ÿã˜ã¦ã„ã¾ã™
- ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã¯æœ€å°é™ã«ã—ã€å…±æ„Ÿã¨ç†è§£ã‚’ç¤ºã™ã“ã¨ã«é‡ç‚¹ã‚’ç½®ã„ã¦ãã ã•ã„
- ã€Œãã†ã ã£ãŸã‚“ã§ã™ã­ã€ã€Œå¤§å¤‰ã§ã—ãŸã­ã€ãªã©ã€å—å®¹çš„ãªå¿œç­”ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„
""",
        'solution': """
ã€ãƒ‹ãƒ¼ã‚º: è§£æ±ºç­–æç¤ºã€‘
- ç›¸è«‡è€…ã¯å…·ä½“çš„ãªè§£æ±ºç­–ã‚„ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æ±‚ã‚ã¦ã„ã¾ã™
- å®Ÿè·µçš„ã§å…·ä½“çš„ãªææ¡ˆã‚’è¡Œã£ã¦ãã ã•ã„
- ãŸã ã—ã€æŠ¼ã—ä»˜ã‘ã«ãªã‚‰ãªã„ã‚ˆã†ã€è¤‡æ•°ã®é¸æŠè‚¢ã‚’æç¤ºã—ã¦ãã ã•ã„
""",
        'thinking': """
ã€ãƒ‹ãƒ¼ã‚º: å…±ã«è€ƒãˆã‚‹ã€‘
- ç›¸è«‡è€…ã¯ä¸€ç·’ã«è€ƒãˆã¦ã»ã—ã„ã¨æ„Ÿã˜ã¦ã„ã¾ã™
- è³ªå•ã‚’é€šã˜ã¦ç›¸è«‡è€…è‡ªèº«ã®è€ƒãˆã‚’å¼•ãå‡ºã—ã¦ãã ã•ã„
- æ„æ€æ±ºå®šã®ã‚µãƒãƒ¼ãƒˆã‚’ã—ã¤ã¤ã€æœ€çµ‚åˆ¤æ–­ã¯ç›¸è«‡è€…ã«å§”ã­ã¦ãã ã•ã„
"""
    }
    
    prompt = base_guardrails + risk_prompts.get(risk_level, risk_prompts[1]) + needs_prompts.get(needs_type, needs_prompts['listening'])
    
    return prompt


def generate_conversation_summary(chat_history: List[Dict], api_key: str) -> str:
    """ä¼šè©±å…¨ä½“ã®ã¾ã¨ã‚ã‚’ç”Ÿæˆ"""
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.5-flash-lite')
        
        # ä¼šè©±å±¥æ­´ã‚’æ•´å½¢
        conversation_text = ""
        for msg in chat_history:
            if msg['role'] == 'user':
                conversation_text += f"ç›¸è«‡è€…: {msg['content']}\n"
            else:
                conversation_text += f"AI: {msg['content']}\n"
        
        summary_prompt = f"""
ä»¥ä¸‹ã¯å­¦ç”Ÿç›¸è«‡ã‚·ã‚¹ãƒ†ãƒ ã§ã®ä¼šè©±å±¥æ­´ã§ã™ã€‚ã“ã®ä¼šè©±ã‚’æŒ¯ã‚Šè¿”ã‚Šã€ä»¥ä¸‹ã®è¦³ç‚¹ã§ã¾ã¨ã‚ã¦ãã ã•ã„:

ã€ä¼šè©±å±¥æ­´ã€‘
{conversation_text}

ã€ã¾ã¨ã‚ã‚‹å†…å®¹ã€‘
1. ç›¸è«‡ã®ä¸»ãªãƒ†ãƒ¼ãƒï¼ˆ2-3è¡Œï¼‰
2. ç›¸è«‡è€…ã®æ°—æŒã¡ã‚„çŠ¶æ³ï¼ˆ2-3è¡Œï¼‰
3. è©±ã—åˆã£ãŸå†…å®¹ã®ãƒã‚¤ãƒ³ãƒˆï¼ˆ3-5é …ç›®ã€ç®‡æ¡æ›¸ãï¼‰
4. ä»Šå¾Œã«å‘ã‘ã¦ã®ãƒ’ãƒ³ãƒˆï¼ˆ2-3è¡Œï¼‰

æ¸©ã‹ãã€å‰å‘ããªãƒˆãƒ¼ãƒ³ã§ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚å°‚é–€ç”¨èªã¯é¿ã‘ã€ç›¸è«‡è€…ãŒè‡ªåˆ†ã®çŠ¶æ³ã‚’å®¢è¦³çš„ã«æŒ¯ã‚Šè¿”ã‚Œã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚
"""
        
        generation_config = {
            "temperature": 0.5,
            "max_output_tokens": 800,
        }
        
        response = model.generate_content(summary_prompt, generation_config=generation_config)
        return response.text
        
    except Exception as e:
        return f"ã¾ã¨ã‚ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)[:150]}"


def generate_ai_response_gemini(user_message: str, risk_level: int, needs_type: str, chat_history: List[Dict], api_key: str) -> str:
    """Gemini APIã‚’ä½¿ç”¨ã—ã¦AIå¿œç­”ã‚’ç”Ÿæˆ"""
    try:
        genai.configure(api_key=api_key)
        
        # 2025å¹´1æœˆæ™‚ç‚¹ã§ç„¡æ–™æ ã§ä½¿ç”¨ã§ãã‚‹æœ€æ–°ãƒ¢ãƒ‡ãƒ«
        # gemini-2.5-flash: 10 RPM, 250K TPM, 250 RPD (ãƒãƒ©ãƒ³ã‚¹å‹)
        # gemini-2.5-flash-lite: 15 RPM, 250K TPM, 1000 RPD (é«˜ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ)
        models_to_try = [
            'gemini-2.5-flash-lite',  # æœ€é«˜ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã€1æ—¥1000ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            'gemini-2.5-flash',       # ãƒãƒ©ãƒ³ã‚¹å‹ã€1æ—¥250ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            'gemini-1.5-flash'        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®å®‰å®šç‰ˆ
        ]
        
        system_prompt = generate_system_prompt(risk_level, needs_type)
        
        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’æ§‹ç¯‰ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›ã®ãŸã‚æœ€æ–°4ä»¶ã®ã¿ï¼‰
        history_text = ""
        for msg in chat_history[-4:]:
            if msg['role'] == 'user':
                history_text += f"ç›¸è«‡è€…: {msg['content']}\n"
            else:
                history_text += f"AI: {msg['content']}\n"
        
        full_prompt = f"{system_prompt}\n\nã€ä¼šè©±å±¥æ­´ã€‘\n{history_text}\n\nã€ç¾åœ¨ã®ç›¸è«‡ã€‘\nç›¸è«‡è€…: {user_message}\n\nAI:"
        
        last_error = None
        for model_name in models_to_try:
            try:
                model = genai.GenerativeModel(model_name)
                
                # å®‰å…¨è¨­å®šã‚’è¿½åŠ ï¼ˆä¸é©åˆ‡ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ãƒ–ãƒ­ãƒƒã‚¯ï¼‰
                safety_settings = [
                    {
                        "category": "HARM_CATEGORY_HARASSMENT",
                        "threshold": "BLOCK_NONE"
                    },
                    {
                        "category": "HARM_CATEGORY_HATE_SPEECH",
                        "threshold": "BLOCK_NONE"
                    },
                    {
                        "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                        "threshold": "BLOCK_NONE"
                    },
                    {
                        "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                        "threshold": "BLOCK_NONE"
                    }
                ]
                
                generation_config = {
                    "temperature": 0.7,
                    "top_p": 0.9,
                    "max_output_tokens": 500,  # å¿œç­”ã‚’ç°¡æ½”ã«ä¿ã¤
                }
                
                response = model.generate_content(
                    full_prompt,
                    safety_settings=safety_settings,
                    generation_config=generation_config
                )
                return response.text
            except Exception as e:
                last_error = e
                continue
        
        # ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã§å¤±æ•—ã—ãŸå ´åˆ
        error_msg = str(last_error)
        if "429" in error_msg or "quota" in error_msg.lower():
            return """
ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ç¾åœ¨ã€APIã®åˆ©ç”¨åˆ¶é™ã«é”ã—ã¦ã„ã¾ã™ã€‚

**è§£æ±ºæ–¹æ³•:**
- æ•°åˆ†å¾…ã£ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„
- 1æ—¥ã®åˆ¶é™ã«é”ã—ãŸå ´åˆã¯ã€ç¿Œæ—¥00:00ï¼ˆå¤ªå¹³æ´‹æ™‚é–“ï¼‰ã«ãƒªã‚»ãƒƒãƒˆã•ã‚Œã¾ã™

**ç„¡æ–™æ ã®åˆ¶é™:**
- 1åˆ†é–“ã«10-15ãƒªã‚¯ã‚¨ã‚¹ãƒˆ (RPM)
- 1æ—¥ã«250-1,000ãƒªã‚¯ã‚¨ã‚¹ãƒˆ (RPD)
  - Gemini 2.5 Flash: 250ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/æ—¥
  - Gemini 2.5 Flash-Lite: 1,000ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/æ—¥
- 1åˆ†é–“ã«250,000ãƒˆãƒ¼ã‚¯ãƒ³ (TPM)

**ä»Šã™ãç›¸è«‡ã—ãŸã„å ´åˆ:**
- å­¦æ ¡ã®ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼
- ä¿å¥å®¤ã®å…ˆç”Ÿ
- ã„ã®ã¡ã®é›»è©±: 0120-783-556ï¼ˆ24æ™‚é–“å¯¾å¿œï¼‰
"""
        else:
            return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãã—ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚\n\nã‚¨ãƒ©ãƒ¼è©³ç´°: {error_msg[:150]}"
        
    except Exception as e:
        return f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)[:150]}\n\nAPIã‚­ãƒ¼ãŒæ­£ã—ã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚"


# UIæ§‹ç¯‰
st.title("ğŸ’­ å­¦ç”Ÿç›¸è«‡æ”¯æ´ã‚·ã‚¹ãƒ†ãƒ ")

# APIã‚­ãƒ¼å…¥åŠ›ã‚¨ãƒªã‚¢
if not st.session_state.api_key_set:
    st.info("ğŸ”‘ Google Gemini APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    
    st.success("""
    **2025å¹´1æœˆæ™‚ç‚¹ã®ç„¡æ–™æ æƒ…å ±:**
    - ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: Gemini 2.5 Flash / Flash-Lite
    - Flash-Lite: 1æ—¥1,000ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¾ã§ï¼ˆé«˜é€Ÿï¼‰
    - Flash: 1æ—¥250ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¾ã§ï¼ˆé«˜å“è³ªï¼‰
    - ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚«ãƒ¼ãƒ‰ä¸è¦
    
    å­¦ç”Ÿç›¸è«‡ã«ååˆ†ãªå®¹é‡ã§ã™ï¼
    """)
    
    api_key_input = st.text_input(
        "APIã‚­ãƒ¼", 
        type="password",
        help="APIã‚­ãƒ¼ã¯Google AI Studioã§å–å¾—ã§ãã¾ã™"
    )
    
    col1, col2 = st.columns(2)
    with col1:
        if st.button("APIã‚­ãƒ¼ã‚’è¨­å®š", type="primary", use_container_width=True):
            if api_key_input:
                st.session_state.api_key = api_key_input
                st.session_state.api_key_set = True
                st.rerun()
            else:
                st.error("APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    
    with col2:
        st.link_button(
            "APIã‚­ãƒ¼ã‚’å–å¾—",
            "https://aistudio.google.com/app/apikey",
            use_container_width=True
        )
    
    st.markdown("---")
    st.markdown("""
    ### ğŸ“± ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã«ã¤ã„ã¦
    
    å­¦ç”Ÿã®çš†ã•ã‚“ãŒå®‰å¿ƒã—ã¦ç›¸è«‡ã§ãã‚‹å ´ã‚’æä¾›ã—ã¾ã™ã€‚
    
    **ç‰¹å¾´:**
    - âœ… AIã«ã‚ˆã‚‹å‚¾è´ã¨æ”¯æ´
    - âœ… ã‚ãªãŸã®ãƒ‹ãƒ¼ã‚ºã«åˆã‚ã›ãŸå¿œç­”
    - âœ… å¿…è¦ã«å¿œã˜ã¦å°‚é–€å®¶ã¸ã®é€£æº
    
    **æ³¨æ„äº‹é …:**
    - âš ï¸ ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯å°‚é–€çš„ãªåŒ»ç™‚ã‚„ã‚«ã‚¦ãƒ³ã‚»ãƒªãƒ³ã‚°ã®ä»£æ›¿ã§ã¯ã‚ã‚Šã¾ã›ã‚“
    - âš ï¸ ç·Šæ€¥æ™‚ã¯å¿…ãšå°‚é–€å®¶ã«ã”ç›¸è«‡ãã ã•ã„
    - ğŸ”’ ç›¸è«‡å†…å®¹ã¯å®‰å…¨ã«ç®¡ç†ã•ã‚Œã¾ã™
    """)
    
else:
    # ãƒ¡ã‚¤ãƒ³ãƒãƒ£ãƒƒãƒˆã‚¨ãƒªã‚¢
    
    # ãƒˆãƒƒãƒ—ãƒãƒ¼ãƒ¡ãƒ‹ãƒ¥ãƒ¼
    col1, col2, col3, col4 = st.columns([2, 1, 1, 1])
    with col1:
        st.markdown("### ğŸ’¬ ç›¸è«‡çª“å£")
    with col2:
        if st.button("ğŸ“ ã¾ã¨ã‚", use_container_width=True, disabled=len(st.session_state.chat_history) < 2):
            if len(st.session_state.chat_history) >= 2:
                with st.spinner("ä¼šè©±ã‚’ã¾ã¨ã‚ã¦ã„ã¾ã™..."):
                    st.session_state.summary = generate_conversation_summary(
                        st.session_state.chat_history,
                        st.session_state.api_key
                    )
                    st.session_state.show_summary = True
    with col3:
        if st.button("â„¹ï¸ æƒ…å ±", use_container_width=True):
            st.session_state.show_info = not st.session_state.show_info
    with col4:
        if st.button("ğŸ”„ ãƒªã‚»ãƒƒãƒˆ", use_container_width=True):
            st.session_state.chat_history = []
            st.session_state.current_risk_level = 0
            st.session_state.summary = None
            st.session_state.show_summary = False
            st.rerun()
    
    # æƒ…å ±ãƒ‘ãƒãƒ«ï¼ˆãƒˆã‚°ãƒ«è¡¨ç¤ºï¼‰
    if st.session_state.show_info:
        with st.expander("ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±", expanded=True):
            if st.session_state.chat_history:
                last_message = st.session_state.chat_history[-1]
                if last_message['role'] == 'assistant':
                    needs_labels = {
                        'listening': 'å‚¾è´é‡è¦–',
                        'solution': 'è§£æ±ºç­–æç¤º',
                        'thinking': 'å…±ã«è€ƒãˆã‚‹'
                    }
                    st.info(f"**æ¤œå‡ºãƒ‹ãƒ¼ã‚º:** {needs_labels.get(last_message.get('needs_type', 'listening'))}")
            
            st.warning("""
            **ç·Šæ€¥æ™‚ã®é€£çµ¡å…ˆ:**
            - ã„ã®ã¡ã®é›»è©±: 0120-783-556
            - å­¦æ ¡ã®ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼
            - ä¿å¥å®¤ã®å…ˆç”Ÿ
            """)
            
            if st.button("APIã‚­ãƒ¼ã‚’å¤‰æ›´"):
                st.session_state.api_key_set = False
                st.rerun()
    
    # ã¾ã¨ã‚è¡¨ç¤ºãƒ‘ãƒãƒ«
    if st.session_state.show_summary and st.session_state.summary:
        with st.expander("ğŸ“ ä¼šè©±ã®ã¾ã¨ã‚", expanded=True):
            st.markdown(st.session_state.summary)
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("âœ… é–‰ã˜ã‚‹", use_container_width=True):
                    st.session_state.show_summary = False
                    st.rerun()
            with col2:
                st.download_button(
                    "ğŸ’¾ ä¿å­˜",
                    data=st.session_state.summary,
                    file_name=f"counseling_summary_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                    mime="text/plain",
                    use_container_width=True
                )
    
    st.markdown("---")
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º
    chat_container = st.container()
    with chat_container:
        if not st.session_state.chat_history:
            st.info("ğŸ‘‹ ã“ã‚“ã«ã¡ã¯ã€‚ä½•ã§ã‚‚ãŠè©±ã—ãã ã•ã„ã€‚ã‚ãªãŸã®è©±ã‚’èã‹ã›ã¦ãã ã•ã„ã€‚")
        
        for i, message in enumerate(st.session_state.chat_history):
            if message['role'] == 'user':
                with st.chat_message("user", avatar="ğŸ™‚"):
                    st.write(message['content'])
            else:
                with st.chat_message("assistant", avatar="ğŸ’­"):
                    st.write(message['content'])
                    
                    # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æ©Ÿèƒ½ï¼ˆæœ€æ–°ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã¿ï¼‰
                    if i == len(st.session_state.chat_history) - 1:
                        with st.expander("ã“ã®å¿œç­”ã¯å½¹ã«ç«‹ã¡ã¾ã—ãŸã‹ï¼Ÿ"):
                            col1, col2 = st.columns([1, 2])
                            with col1:
                                rating = st.select_slider(
                                    "è©•ä¾¡", 
                                    options=[1, 2, 3, 4, 5],
                                    value=3,
                                    key=f"rating_{i}"
                                )
                            with col2:
                                if st.button("ğŸ‘ é€ä¿¡", key=f"submit_{i}", use_container_width=True):
                                    feedback = {
                                        'message_id': i,
                                        'rating': rating,
                                        'timestamp': datetime.datetime.now().isoformat()
                                    }
                                    st.session_state.feedback_data.append(feedback)
                                    st.success("ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼")

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ï¼ˆç”»é¢ä¸‹éƒ¨ã«å›ºå®šï¼‰
    st.markdown("---")
    user_input = st.chat_input("ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...")

    if user_input:
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
        st.session_state.chat_history.append({
            'role': 'user',
            'content': user_input,
            'timestamp': datetime.datetime.now().isoformat()
        })
        
        # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«åˆ¤å®š
        risk_level, detected_keywords = analyze_risk_level(user_input)
        st.session_state.current_risk_level = max(st.session_state.current_risk_level, risk_level)
        
        # ãƒ‹ãƒ¼ã‚ºåˆ†æ
        needs_type = analyze_needs(user_input)
        
        # AIå¿œç­”ç”Ÿæˆï¼ˆGeminiä½¿ç”¨ï¼‰
        with st.spinner("è€ƒãˆã¦ã„ã¾ã™..."):
            ai_response = generate_ai_response_gemini(
                user_input, 
                risk_level, 
                needs_type,
                st.session_state.chat_history,
                st.session_state.api_key
            )
        
        # AIå¿œç­”ã‚’è¿½åŠ 
        st.session_state.chat_history.append({
            'role': 'assistant',
            'content': ai_response,
            'timestamp': datetime.datetime.now().isoformat(),
            'risk_level': risk_level,
            'needs_type': needs_type,
            'detected_keywords': detected_keywords
        })
        
        st.rerun()

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.caption("ğŸ’¡ ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯å­¦ç”Ÿã®ç›¸è«‡æ”¯æ´ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚ç·Šæ€¥æ™‚ã¯å¿…ãšå°‚é–€å®¶ã«ã”ç›¸è«‡ãã ã•ã„ã€‚")